---------------------------------------------------------------------------
Training stage 0
Sampled 1800 windows from 604 images.
Done sampling windows (time=21s).
Computing lambdas... done (time=23s).
Extracting features... done (time=3s).
Sampled 14757 windows from 604 images.
Done sampling windows (time=30s).
Extracting features... done (time=38s).
Training AdaBoost: nWeak= 64 nFtrs=20475 pos=1800 neg=14757
 i=  16 alpha=1.000 err=0.092 loss=1.92e-04
 i=  32 alpha=1.000 err=0.102 loss=1.82e-08
 i=  48 alpha=1.000 err=0.108 loss=1.18e-12
 i=  64 alpha=1.000 err=0.092 loss=5.91e-17
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=11.5s).
Done training stage 0 (time=129s).
---------------------------------------------------------------------------
Training stage 1
Sampled 2079 windows from 604 images.
Done sampling windows (time=104s).
Extracting features... done (time=4s).
Training AdaBoost: nWeak=256 nFtrs=20475 pos=1800 neg=16836
 i=  16 alpha=1.000 err=0.252 loss=3.15e-02
 i=  32 alpha=1.000 err=0.232 loss=1.14e-03
 i=  48 alpha=1.000 err=0.227 loss=3.77e-05
 i=  64 alpha=1.000 err=0.239 loss=1.34e-06
 i=  80 alpha=1.000 err=0.232 loss=4.30e-08
 i=  96 alpha=1.000 err=0.213 loss=1.32e-09
 i= 112 alpha=1.000 err=0.240 loss=3.33e-11
 i= 128 alpha=1.000 err=0.193 loss=1.01e-12
 i= 144 alpha=1.000 err=0.226 loss=2.99e-14
 i= 160 alpha=1.000 err=0.232 loss=9.74e-16
 i= 176 alpha=1.000 err=0.227 loss=2.89e-17
 i= 192 alpha=1.000 err=0.219 loss=7.85e-19
 i= 208 alpha=1.000 err=0.225 loss=2.04e-20
 i= 224 alpha=1.000 err=0.213 loss=5.57e-22
 i= 240 alpha=1.000 err=0.229 loss=1.61e-23
 i= 256 alpha=1.000 err=0.205 loss=3.99e-25
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=39.1s).
Done training stage 1 (time=148s).
---------------------------------------------------------------------------
Training stage 2
Sampled 212 windows from 604 images.
Done sampling windows (time=105s).
Extracting features... done (time=1s).
Training AdaBoost: nWeak=1024 nFtrs=20475 pos=1800 neg=17048
 i=  16 alpha=1.000 err=0.239 loss=4.20e-02
 i=  32 alpha=1.000 err=0.241 loss=2.81e-03
 i=  48 alpha=1.000 err=0.243 loss=1.60e-04
 i=  64 alpha=1.000 err=0.240 loss=8.16e-06
 i=  80 alpha=1.000 err=0.250 loss=3.82e-07
 i=  96 alpha=1.000 err=0.237 loss=1.95e-08
 i= 112 alpha=1.000 err=0.230 loss=8.71e-10
 i= 128 alpha=1.000 err=0.231 loss=4.25e-11
 i= 144 alpha=1.000 err=0.228 loss=1.84e-12
 i= 160 alpha=1.000 err=0.236 loss=8.78e-14
 i= 176 alpha=1.000 err=0.251 loss=4.27e-15
 i= 192 alpha=1.000 err=0.234 loss=1.77e-16
 i= 208 alpha=1.000 err=0.238 loss=6.87e-18
 i= 224 alpha=1.000 err=0.245 loss=2.76e-19
 i= 240 alpha=1.000 err=0.245 loss=1.15e-20
 i= 256 alpha=1.000 err=0.245 loss=4.85e-22
 i= 272 alpha=1.000 err=0.229 loss=2.22e-23
 i= 288 alpha=1.000 err=0.230 loss=9.07e-25
 i= 304 alpha=1.000 err=0.241 loss=4.47e-26
 i= 320 alpha=1.000 err=0.249 loss=2.01e-27
 i= 336 alpha=1.000 err=0.246 loss=9.71e-29
 i= 352 alpha=1.000 err=0.261 loss=4.48e-30
 i= 368 alpha=1.000 err=0.251 loss=2.17e-31
 i= 384 alpha=1.000 err=0.244 loss=9.91e-33
 i= 400 alpha=1.000 err=0.251 loss=4.65e-34
 i= 416 alpha=1.000 err=0.239 loss=2.26e-35
 i= 432 alpha=1.000 err=0.245 loss=9.52e-37
 i= 448 alpha=1.000 err=0.257 loss=3.85e-38
 i= 464 alpha=1.000 err=0.256 loss=1.75e-39
 stopping early
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=86.6s).
Done training stage 2 (time=193s).
---------------------------------------------------------------------------
Training stage 3
Sampled 76 windows from 604 images.
Done sampling windows (time=106s).
Extracting features... done (time=0s).
Training AdaBoost: nWeak=4096 nFtrs=20475 pos=1800 neg=17124
 i=  16 alpha=1.000 err=0.250 loss=4.84e-02
 i=  32 alpha=1.000 err=0.237 loss=3.33e-03
 i=  48 alpha=1.000 err=0.239 loss=1.84e-04
 i=  64 alpha=1.000 err=0.255 loss=9.95e-06
 i=  80 alpha=1.000 err=0.246 loss=5.56e-07
 i=  96 alpha=1.000 err=0.260 loss=2.94e-08
 i= 112 alpha=1.000 err=0.212 loss=1.31e-09
 i= 128 alpha=1.000 err=0.243 loss=6.17e-11
 i= 144 alpha=1.000 err=0.254 loss=3.10e-12
 i= 160 alpha=1.000 err=0.248 loss=1.73e-13
 i= 176 alpha=1.000 err=0.234 loss=7.69e-15
 i= 192 alpha=1.000 err=0.246 loss=3.61e-16
 i= 208 alpha=1.000 err=0.255 loss=1.65e-17
 i= 224 alpha=1.000 err=0.257 loss=7.61e-19
 i= 240 alpha=1.000 err=0.249 loss=3.59e-20
 i= 256 alpha=1.000 err=0.241 loss=1.72e-21
 i= 272 alpha=1.000 err=0.245 loss=8.20e-23
 i= 288 alpha=1.000 err=0.222 loss=3.71e-24
 i= 304 alpha=1.000 err=0.219 loss=1.85e-25
 i= 320 alpha=1.000 err=0.253 loss=8.06e-27
 i= 336 alpha=1.000 err=0.248 loss=3.88e-28
 i= 352 alpha=1.000 err=0.232 loss=1.71e-29
 i= 368 alpha=1.000 err=0.247 loss=7.45e-31
 i= 384 alpha=1.000 err=0.231 loss=3.55e-32
 i= 400 alpha=1.000 err=0.247 loss=1.77e-33
 i= 416 alpha=1.000 err=0.240 loss=9.13e-35
 i= 432 alpha=1.000 err=0.237 loss=5.01e-36
 i= 448 alpha=1.000 err=0.248 loss=2.60e-37
 i= 464 alpha=1.000 err=0.232 loss=1.40e-38
 i= 480 alpha=1.000 err=0.249 loss=5.81e-40
 stopping early
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=99.1s).
Done training stage 3 (time=206s).
---------------------------------------------------------------------------
Done training (time=677s).
